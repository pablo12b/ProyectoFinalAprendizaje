{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evidencia de Funcionalidad: Agente con Reconocimiento Visual\n",
                "\n",
                "Este notebook demuestra la integración final donde el **Planner (Search Service)** es capaz de utilizar la nueva herramienta de **Reconocimiento de Imagen**.\n",
                "\n",
                "Se simula el flujo de un agente que decide usar la herramienta correcta basándose en la petición del usuario.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from unittest.mock import MagicMock, AsyncMock\n",
                "\n",
                "# Setup paths\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "from business_backend.services.search_service import SearchService, SearchResult\n",
                "from business_backend.ml.serving.inference_service import InferenceService, PredictionResult\n",
                "from business_backend.ml.models.registry import ModelRegistry, BaseModel\n",
                "from business_backend.llm.provider import LLMProvider\n",
                "from business_backend.llm.tools.image_recognition_tool import ImageRecognitionTool"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuración de Mocks\n",
                "\n",
                "Para esta demostración aislada, simulamos:\n",
                "1.  **ProductService**: Base de datos de productos.\n",
                "2.  **InferenceService**: El servicio ML que creamos anteriormente.\n",
                "3.  **LLMProvider**: Simulamos la decisión del LLM de llamar a una tool.\n",
                "\n",
                "Esto prueba la lógica de orquestación en `SearchService` sin gastar tokens de OpenAI."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Mock Product Service\n",
                "product_service_mock = AsyncMock()\n",
                "product_service_mock.search_by_name.return_value = [] # Default empty\n",
                "\n",
                "# 2. Mock Inference Service (Using logic similar to real one)\n",
                "inference_service_mock = AsyncMock(spec=InferenceService)\n",
                "inference_service_mock.predict.return_value = PredictionResult(\n",
                "    model_name=\"product_classifier\",\n",
                "    prediction=\"Leche Entera 1L\",\n",
                "    confidence=0.99\n",
                ")\n",
                "\n",
                "# 3. Mock LLM Provider that simulates tool calling\n",
                "llm_provider_mock = MagicMock(spec=LLMProvider)\n",
                "mock_model = AsyncMock()\n",
                "llm_provider_mock.bind_tools.return_value = mock_model\n",
                "\n",
                "# Simular respuesta del LLM diciendo \"Hey, usa la herramienta image_recognition con esta imagen\"\n",
                "tool_call_response = MagicMock()\n",
                "tool_call_response.tool_calls = [\n",
                "    {\n",
                "        \"name\": \"image_recognition\",\n",
                "        \"args\": {\"image_path\": \"/path/to/leche.jpg\"},\n",
                "        \"id\": \"call_123\"\n",
                "    }\n",
                "]\n",
                "tool_call_response.content = \"Voy a analizar la imagen.\"\n",
                "\n",
                "# Simular respuesta final después de usar la herramienta\n",
                "final_response = MagicMock()\n",
                "final_response.content = \"He analizado la imagen y veo que es 'Leche Entera 1L'.\"\n",
                "final_response.tool_calls = None\n",
                "\n",
                "# Configurar el side_effect para devolver primero la llamada a tool, luego la respuesta final\n",
                "mock_model.ainvoke.side_effect = [tool_call_response, final_response]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Inyección de Dependencias\n",
                "\n",
                "Aquí es donde ocurre la magia de la integración. Inyectamos, además del servicio de productos, el `inference_service` al `SearchService`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "search_service = SearchService(\n",
                "    llm_provider=llm_provider_mock,\n",
                "    product_service=product_service_mock,\n",
                "    inference_service=inference_service_mock  # <--- Integración clave\n",
                ")\n",
                "\n",
                "print(\"SearchService inicializado.\")\n",
                "if search_service.image_tool:\n",
                "    print(\"✅ Herramienta de Imagen registrada correctamente en el servicio.\")\n",
                "else:\n",
                "    print(\"❌ Fallo al registrar herramienta de imagen.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Ejecución del Agente\n",
                "\n",
                "Simulamos un usuario preguntando: *\"¿Qué es esto?\"* enviando una imagen.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"¿Qué producto es este? /path/to/leche.jpg\"\n",
                "\n",
                "result = await search_service.semantic_search(query)\n",
                "\n",
                "print(\"\\n--- Resultado Final del Agente ---\\n\")\n",
                "print(f\"Respuesta: {result.answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Verificación de Llamadas Internas\n",
                "\n",
                "Verificamos que el Agente realmente llamó al servicio de ML por debajo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verificar que se llamó al InferenceService\n",
                "inference_service_mock.predict.assert_called_once()\n",
                "call_args = inference_service_mock.predict.call_args\n",
                "\n",
                "print(\"Validación de Integración:\")\n",
                "print(f\"✅ Se llamó a 'InferenceService.predict'? {inference_service_mock.predict.called}\")\n",
                "print(f\"✅ Argumentos usados: {call_args}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusión\n",
                "\n",
                "Esta evidencia demuestra que el **Planner** ahora tiene capacidad **Multimodal**. \n",
                "Si el usuario pregunta sobre una imagen, el sistema:\n",
                "1. Detecta la intención.\n",
                "2. Invoca `image_recognition_tool`.\n",
                "3. La tool usa `InferenceService` para clasificar.\n",
                "4. El LLM interpreta la clasificación y responde al usuario."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}